# -*- coding: utf-8 -*-
"""Proyecto final de Tópicos de Inteligencia Computacional.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hLqxjAQCtGS_B4HngQ3KURF1J1ccFvd5
"""

pip install spello

pip install PyPDF2

from spello.model import SpellCorrectionModel
import re
import PyPDF2
from PyPDF2 import PdfReader
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize
from rmv import rcv

pdf_files = ["aa.pdf", "bb.pdf", "cc.pdf", "dd.pdf", "ee.pdf", "ff.pdf",
             "gg.pdf", "hh.pdf", "ii.pdf", "jj.pdf", "kk.pdf", "ll.pdf",
             "mm.pdf", "nn.pdf", "oo.pdf", "pp.pdf", "qq.pdf", "rr.pdf"]

def preprocesamiento(cadena):
  cadena_preprocesada = re.sub(r'[^\w\s]', '', cadena)
  cadena_preprocesada = re.sub(r'\d+', '', cadena_preprocesada)
  cadena_preprocesada = re.sub(r'http\S+|www\S+', '', cadena_preprocesada, flags=re.MULTILINE)
  cadena_preprocesada = re.sub(r'\S+@\S+', '', cadena_preprocesada, flags=re.MULTILINE)
  return cadena_preprocesada.lower()

def oraciones_limpieza(cadenas):
  cadenas_limpias = []
  for oracion in cadenas:
    oracion = preprocesamiento(oracion)
    if len(oracion.strip()) == 0 or len(oracion) < 10:
        continue
    else:
      cadenas_limpias.append(oracion.strip())
  return cadenas_limpias

def obtener_oraciones(nombre_archivo):
    try:
        with open(nombre_archivo, 'r') as archivo:
            # Leer todas las líneas del archivo y eliminar el caracter de nueva línea
            lineas = [linea.strip() for linea in archivo.readlines()]

            # Si hay alguna línea en blanco, eliminarla
            lineas = [linea for linea in lineas if linea]

            return lineas
    except FileNotFoundError:
        print(f"El archivo '{nombre_archivo}' no se encontró.")
        return []

# Llamar a la función y obtener las oraciones del archivo
nombre_archivo1 = "test_correct.txt"
nombre_archivo2 = "test_incorrect.txt"
oraciones_test_correctas = obtener_oraciones(nombre_archivo1)
oraciones_test_incorrectas = obtener_oraciones(nombre_archivo2)

test_correctas = oraciones_limpieza(oraciones_test_correctas)
test_incorrectas = oraciones_limpieza(oraciones_test_incorrectas)

orcs = oraciones_limpieza(rcv)
def extract_sentences_from_pdf(pdf_paths):
    all_text = ""

    for pdf_path in pdf_paths:
        reader = PdfReader(pdf_path)
        number_of_pages = len(reader.pages)

        for page_num in range(number_of_pages):
            page = reader.pages[page_num]
            all_text += page.extract_text()

    sentence_list = sent_tokenize(all_text)
    return sentence_list

sentences = extract_sentences_from_pdf(pdf_files)
sentences_new = oraciones_limpieza(sentences)

print(len(sentences),len(sentences_new))

sentences_new

def extract_text_from_multiple_pdfs(pdf_paths):
    all_text = ""

    for pdf_path in pdf_paths:
        reader = PdfReader(pdf_path)
        number_of_pages = len(reader.pages)

        for page_num in range(number_of_pages):
            page = reader.pages[page_num]
            all_text += page.extract_text()

    return all_text

palabras = extract_text_from_multiple_pdfs(pdf_files)
print(palabras)

len(palabras)

def remove_newlines_with_re(input_string):
    # Utilizando re.sub para eliminar las nuevas líneas
    cleaned_string = re.sub(r'\n', '', input_string)
    return cleaned_string

def extract_words_to_list(input_string):
    # Utilizando el método split para dividir el string en palabras
    word_list = input_string.split()
    return word_list

# Usando la función con re.sub para eliminar \n
cleaned_text_with_re = remove_newlines_with_re(palabras)
cleaned_text_with_re = cleaned_text_with_re.lower()
sentences_new.extend(orcs)
word_list = extract_words_to_list(cleaned_text_with_re)
print("\nTexto limpio con re.sub:")
print(word_list)

len(word_list)

sentences_new.extend(word_list)

len(sentences_new)

sp = SpellCorrectionModel(language='en')

sp.train(sentences_new)

import matplotlib.pyplot as plt

def calcular_precision(test_incorrectas, test_correctas):
    total_oraciones = len(test_incorrectas)
    cont_correctas = 0

    for oracion_wrong, oracion_right in zip(test_incorrectas, test_correctas):
        verificar = sp.spell_correct(oracion_wrong)
        if verificar['spell_corrected_text'] == oracion_right:
            cont_correctas += 1

    precision = (cont_correctas / total_oraciones) * 100
    return precision

# Suponiendo que tienes las listas test_incorrectas y test_correctas como mencioné anteriormente
precision_resultado = calcular_precision(test_incorrectas, test_correctas)
print(f"Precisión: {precision_resultado:.2f}%")

# Crear el gráfico circular
labels = ['Correctas', 'Incorrectas']
sizes = [precision_resultado, 100 - precision_resultado]
colors = ['#ff9999', '#66b3ff']
explode = (0.1, 0)  # Separación de la primera porción

plt.figure(figsize=(6, 6))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
plt.axis('equal')  # Equal aspect ratio asegura que el gráfico sea circular.
plt.title('Precisión de las oraciones')
plt.show()

sentence = test_incorrectas[1]
ver = sp.spell_correct(sentence)

sentence = 'I uant to brek free'
ver = sp.spell_correct(sentence)
print('\n',f"Texto original: {ver['original_text']}",'\n',f"Texto corregido: {ver['spell_corrected_text']}",'\n',f"Palabras corregidas: {ver['correction_dict']}")

sentence = 'I wll meet you agan'
ver = sp.spell_correct(sentence)
print('\n',f"Texto original: {ver['original_text']}",'\n',f"Texto corregido: {ver['spell_corrected_text']}",'\n',f"Palabras corregidas: {ver['correction_dict']}")

sentence = 'new technolgy has been introducd inyo the societ'
ver = sp.spell_correct(sentence)
print('\n',f"Texto original: {ver['original_text']}",'\n',f"Texto corregido: {ver['spell_corrected_text']}",'\n',f"Palabras corregidas: {ver['correction_dict']}")

sentence = 'approaches for the calibrasion of neural networks and give an overview of existing baselines and available implementations. Different examples from the wide spectrum of challenges in the fields of medical image analysis robotik and earth observation give an idea of the needs and challenges regarding unsertaintties hin practical applications of neurall networks'
ver = sp.spell_correct(sentence)
print('\n',f"Texto original: {ver['original_text']}",'\n',f"Texto corregido: {ver['spell_corrected_text']}",'\n',f"Palabras corregidas: {ver['correction_dict']}")